<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">
  <title>yousirong CV</title>
  <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico">
  <!-- Font Awesome icons (free version)-->
  <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
  <!-- Google fonts-->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css">
  <!-- Core theme CSS (includes Bootstrap)-->
  <link href="css/styles.css" rel="stylesheet">
</head>
<!-- Navigation-->
<nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav"><a class="navbar-brand js-scroll-trigger" href="#page-top"><span class="d-block d-lg-none">JuneyongLee CV</span><span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile.jpg" alt="..."></span></a>
  <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
  <div class="collapse navbar-collapse" id="navbarResponsive">
    <ul class="navbar-nav">
      <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
      <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
      <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
      <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
      <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Research project</a></li>
      <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li>
    </ul>
  </div>
</nav>
<!-- Page Content-->
<div class="container-fluid p-0">
  <!-- About-->
  <section class="resume-section" id="about">
    <div class="resume-section-content">
      <h1 class="mb-0">JUNEYONG<span class="text-primary">LEE</span></h1>
      <div class="subheading mb-5">Seoul, Republic of Korea  &middot; +82 10-5384-7822 &middot;<a href="mailto:diziyong@hufs.ac.kr">diziyong@hufs.ac.kr</a></div>
      <p class="lead mb-5">
        Hello, I am June-yong Lee, currently pursuing a master&apos;s degree in computer engineering
        at Hankuk University of Foreign Studies. I am interested in applying diffusion models to autonomous driving research,
        with a particular focus on deep learning computer vision, generative AI, and multimodal AI.
        One of my research papers, titled &quot;Lightweight Temporal Segment Network for Video Scene Understanding:
        Validation of Driver Assault Detection,&quot;
        was published in the Journal of the Korean Institute of Information Scientists and Engineers (KIISE).
        I also have experience developing and deploying responsive web interfaces for web crawling servers,
        making me proficient in frontend, backend, and web crawling technologies.
        My current research interests include transformer-based diffusion models.
      </p>
      <div class="social-icons"><a class="social-icon" href="https://www.linkedin.com/in/juneyong-%E2%80%8Dlee-05b09733a/"><i class="fab fa-linkedin-in"></i></a><a class="social-icon" href="https://github.com/yousirong"><i class="fab fa-github"></i></a><a class="social-icon" href="https://www.instagram.com/juneyong_d.v/"><i class="fab fa-instagram"></i></a><a class="social-icon" href="https://scholar.google.com/citations?hl=ko&amp;view_op=list_works&amp;authuser=2&amp;gmla=AFix5MZtqvevqzAeIhXMiafiBydfjIGYBE9MqJrFJ-getmKb7ggOrjFXHU6xSQB1MwIpcABG6BxX8uDZHHWsysThrITyAy1KJ_3apoPWzonXcUobFA&amp;user=VAbPjjoAAAAJ"><i class="fa-solid fa-graduation-cap"></i></a></div>
    </div>
  </section>
  <hr class="m-0">
  <!-- Publications-->
  <section class="resume-section" id="publications">
    <div class="resume-section-content">
      <h2 class="mb-5">Publications</h2>
      <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="flex-grow-1">
          <h3 class="mb-0">ADPDiT: A Multimodal Diffusion Transformer for Predicting Alzheimer's Disease Progression and Generating Brain Image</h3>
          <div class="subheading mb-3">Journal undecided</div>
          <p>
            ADPDiT (Alzheimer’s Disease Progression Diffusion Trans- former) is a novel multimodal framework that integrates brain MRI data with structured textual metadata to predict Alzheimer’s disease (AD) progression and generate personalized, progression-conditioned AD brain images. 
            AD is a progressive neurodegenerative disorder with complex pathology, and conventional single-modality diagnostic approaches such as brain imaging or cognitive assessments fail to capture its full complex- ity.
            To overcome these limitations, ADPDiT employs a diffusion transformer with cross-attention modules to effectively fuse patient-specific anatomical features with auxiliary metadata. 
            The model also leverages a VAE-based latent space and incorporates Rotary Position Encoding (RoPE) to enhance the alignment between image and text embeddings, thereby accelerating convergence and improving accuracy.
            In this study, brain MRI data from 1,171 participants in the Alzheimer’s Disease Neu- roimaging Initiative (ADNI) dataset, comprising 377 cognitively normal individuals, 540 mild cognitive impairment cases, and 254 AD patients, were used for training and evaluation.
            The dataset was rigorously pre- processed with image alignment, normalization, spatial resolution adjustment, and histogram equalization to ensure high-quality inputs. 
            Additionally, clinical metadata including cognitive test scores (MMSE, CDR, etc.) were embedded in the latent space to guide the generative process.
            By combining multimodal conditioning with transformer-based diffusion modeling, ADPDiT offers a comprehensive approach to AD diagnosis and research, providing insights into disease progression and facilitating the development of precision medicine tools for neurodegenerative disorders.
            This study demonstrates that ADPDiT, through its integration of dif- fusion processes and multimodal data, is a promising tool for advancing precision medicine in the diagnosis and management of AD.
          </p><span class="sreen"><a href="https://github.com/Deep-Generative-Models-research">https://github.com/Deep-Generative-Models-research</a></span>
          <p><span class="badge text-body border border-1">Alzheimer’s Disease (AD)</span><span class="badge text-body border border-1">Text-Guided Image Generation</span><span class="badge text-body border border-1">Brain MRI Generation</span></p>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">1st semester 2025</span></div>
      </div>
      <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="flex-grow-1">
          <h3 class="mb-0">
            Lightweight Temporal Segment Network for Video Scene Understanding:
            Validation in Driver Assault Detection
          </h3>
          <div class="subheading mb-3">Korean Institute of Information Scientists and Engineers - Journal of KIISE(JOK)</div>
          <p>
            There has been increasing number of driver assaults in transportation such as taxis and buses in the past years.
            It can be especially difficult to respond quickly to assaults on drivers by drunks late at night.
            To address this issue, our research team proposes a lightweight CNN-based Temporal Segment Network (TSN) model,
            which can detect driver assaults by passengers in real time.
            The TSN model efficiently processes videos by sampling a small number of image frames and is divided into two streams for learning:
            one for spatial information processing and the other for temporal information processing.
            Convolutional neural networks are employed in each stream. In this research,
            we apply a lightweight CNN architecture, MobileOne, significantly reducing the model size while demonstrating improved accuracy even with limited computing resources.
            The model is expected to contribute to rapid response and prevention of hazardous situations for drivers by being integrated into vehicular driver monitoring systems.
          </p><span class="sreen"><a href="https://github.com/HUFSuperman/HUFS_SavingDriver">https://github.com/HUFSuperman/HUFS_SavingDriver</a></span>
          <p><span class="badge text-body border border-1">Temporal Segment Network</span><span class="badge text-body border border-1">Lightweight CNN Architecture</span><span class="badge text-body border border-1">Assault Recognition</span><span class="badge text-body border border-1">Abnormal Behavior</span></p>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">1st semester 2024</span></div>
      </div>
      <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="flex-grow-1">
          <h3 class="mb-0">Research on Developing a Responsive Web Interface for Small Businesses Using React</h3>
          <div class="subheading mb-3">Collaboration with PeopleCat Co., Ltd.</div>
          <p>
            Although large corporations have established sales databases for efficient sales
            activities, small-scale entrepreneurs need a system that provides an interface that anyone
            can easily manage, offering diverse and complex information. This paper proposes the use
            of React technology, which can also operate on crawling servers that automatically collect
            store information.
            Furthermore, it suggests the development of a responsive web user interface that can be conveniently used in both mouse
            and keyboard-based desktop environments as well as touch-based smartphone environments,
            utilizing React technology for theeffective delivery of various data. The proposed methods anticipate rapid retrieval of large
            volumes of data due to the adoption of asynchronous function processing in React technology,
            an improvement over traditional JavaScript methods.
          </p><span class="sreen"><a href="https://github.com/yousirong/CAPSTONE_AWS">https://github.com/yousirong/CAPSTONE_AWS</a></span>
          <p><span class="badge text-body border border-1">Responsive Web Interface</span><span class="badge text-body border border-1">React</span><span class="badge text-body border border-1">Asynchronous Processing</span><span class="badge text-body border border-1">Information Architecture Design</span></p>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">2nd semester 2023</span></div>
      </div>
      <!--
      <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
      <div class="flex-grow-1">
      <h3 class="mb-0">Junior Web Designer</h3>
      <div class="subheading mb-3">Shout! Media Productions</div>
      <p>Podcasting operational change management inside of workflows to establish a framework. Taking seamless key performance indicators offline to maximise the long tail. Keeping your eye on the ball while performing a deep dive on the start-up mentality to derive convergence on cross-platform integration.</p>
      </div>
      <div class="flex-shrink-0"><span class="text-primary">July 2010 - December 2011</span></div>
      </div>
      <div class="d-flex flex-column flex-md-row justify-content-between">
      <div class="flex-grow-1">
      <h3 class="mb-0">Web Design Intern</h3>
      <div class="subheading mb-3">Shout! Media Productions</div>
      <p>Collaboratively administrate empowered markets via plug-and-play networks. Dynamically procrastinate B2C users after installed base benefits. Dramatically visualize customer directed convergence without revolutionary ROI.</p>
      </div>
      <div class="flex-shrink-0"><span class="text-primary">September 2008 - June 2010</span></div>
      </div>
      -->
    </div>
  </section>
  <hr class="m-0">
  <!-- Education-->
  <section class="resume-section" id="education">
    <div class="resume-section-content">
      <h2 class="mb-5">Education</h2>
      <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="flex-grow-1">
          <h3 class="mb-0">Master course, Korea University of Foreign Studies</h3>
          <div class="subheading mb-3">Computer Science</div>
          <div>Computer Science - AI Track</div>
          <p>GPA: 4.33</p>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">March 2024 ~ present</span></div>
      </div>
      <div class="d-flex flex-column flex-md-row justify-content-between">
        <div class="flex-grow-1">
          <h3 class="mb-0">Bachelor&apos;s degree, Korea University of Foreign Studies</h3>
          <div class="subheading mb-3">Computer and Electronic Systems Engineering Major</div>
          <p>GPA: 3.50</p>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">March 2021 - February 2024</span></div>
      </div>
      <div class="d-flex flex-column flex-md-row justify-content-between">
        <div class="flex-grow-1">
          <h3 class="mb-0">Bachelor course, Change of Major</h3>
          <div class="subheading mb-3">Computer Science Major</div>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">March 2018 - February 2019</span></div>
      </div>
      <div class="d-flex flex-column flex-md-row justify-content-between">
        <div class="flex-grow-1">
          <h3 class="mb-0">Bachelor course, Admission</h3>
          <div class="subheading mb-3">Statistics and Data Science Major</div>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">March 2017 - February 2018</span></div>
      </div>
    </div>
  </section>
  <hr class="m-0">
  <!-- Skills-->
  <section class="resume-section" id="skills">
    <div class="resume-section-content">
      <h2 class="mb-5">Skills</h2>
      <div class="subheading mb-3">Programming Languages & Tools</div>
      <ul class="list-inline dev-icons">
        <li class="list-inline-item"><a href="https://www.python.org/" title="Python"><img src="https://skillicons.dev/icons?i=py" alt="Python" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://pytorch.org/" title="PyTorch"><img src="https://skillicons.dev/icons?i=pytorch" alt="PyTorch" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://www.linux.org/" title="Linux"><img src="https://skillicons.dev/icons?i=linux" alt="Linux" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://www.docker.com/" title="Docker"><img src="https://skillicons.dev/icons?i=docker" alt="Docker" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://kubernetes.io/" title="Kubernetes"><img src="https://skillicons.dev/icons?i=kubernetes" alt="Kubernetes" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://www.latex-project.org/" title="LaTeX"><img src="https://skillicons.dev/icons?i=latex" alt="LaTeX" style="width:60px; height:60px;"></a></li>
      </ul>
      <div class="subheading mb-3">Workspace</div>
      <ul class="list-inline dev-icons">
        <li class="list-inline-item"><a href="https://git-scm.com/" title="Git"><img src="https://skillicons.dev/icons?i=git" alt="Git" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://code.visualstudio.com/" title="VSCode"><img src="https://skillicons.dev/icons?i=vscode" alt="VSCode" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://aws.amazon.com/" title="AWS"><img src="https://skillicons.dev/icons?i=aws" alt="AWS" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://www.figma.com/" title="Figma"><img src="https://skillicons.dev/icons?i=figma" alt="Figma" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://www.notion.so/" title="Notion"><img src="https://skillicons.dev/icons?i=notion" alt="Notion" style="width:60px; height:60px;"></a></li>
        <li class="list-inline-item"><a href="https://discord.com/" title="Discord"><img src="https://skillicons.dev/icons?i=discord" alt="Discord" style="width:60px; height:60px;"></a></li>
      </ul>
    </div>
  </section>
  <hr class="m-0">
  <!-- Interests-->
  <section class="resume-section" id="interests">
    <div class="resume-section-content">
      <h2 class="mb-5">Research Projects</h2>
      <div class="mb-4">
        <h3>Conversion of Restored Rrs Data to Chl-a and Generation of Difference Map</h3>
        <h4 class="fs-4 fw-normal">Objective:</h4>
        <p>Convert restored Remote Sensing Reflectance (Rrs) data into Chlorophyll-a (Chl‑a) and visualize spatial distribution errors through a Difference Map using composite data.</p>
        <h4 class="fs-4 fw-normal">Main Tasks:</h4>
        <ul>
          <li>Process GOCI data captured 8 times a day into a single daily dataset by averaging pixel values.</li>
          <li>Select specific coordinates in the Saemangeum or Nakdong River region to convert restored Rrs data to Chl‑a and analyze results.</li>
          <li>Calculate the difference between restored results and actual GOCI data, visualizing it using MinMaxScaler with a range of ‑20 to +20, represented in color scale.</li>
        </ul>
        <h4 class="fs-4 fw-normal">Outcome:</h4>
        <p>While successful synthesis results from Rrs to Chl‑a are rare globally, the study introduced a quantitative evaluation method using Difference Maps to assess restoration performance.</p>
      </div>
      <div class="mb-4">
        <h3>Development of a Supervised Learning Model for Restoring Gaps in Chl‑a Composite Data</h3>
        <h4 class="fs-4 fw-normal">Objective:</h4>
        <p>Develop a deep learning model to restore missing regions in Chl‑a composite data, averaged over 8 days.</p>
        <h4 class="fs-4 fw-normal">Main Tasks:</h4>
        <ul>
          <li>Convert UST21 dataset into 8‑day moving averages for model training. For example, calculate averages for January 1–8 and January 2–9, and so on.</li>
          <li>Focus on central regions around Saemangeum and Nakdong River but adjust the area towards the open sea if data availability is limited.</li>
          <li>Train the RFRNet model with masked data for restoration tasks.</li>
        </ul>
        <h4 class="fs-4 fw-normal">Outcome:</h4>
        <ul>
          <li>Compare restored results with MODIS 8‑day average data to evaluate performance.</li>
          <li>Conduct quantitative analysis of restoration results for Nakdong River and Saemangeum regions using RMSE, MAE, and R² metrics.</li>
          <li>Apply smoothing techniques for missing data when testing images larger than the traditional 256×256 patch size.</li>
        </ul>
      </div>
      <div class="mb-4">
        <h3>Wave Overtopping Detection & Tracking Experiment with YOLO v9 and ByteTrack</h3>
        <h4 class="fs-4 fw-normal">Objective:</h4>
        <p>Upgrade the detection model from YOLO v7 to YOLO v9 on both a frontal hydraulic model overtopping dataset and a real breakwater overtopping region, then replace the IOU Tracker with ByteTrack to compare and analyze detection and tracking performance.</p>
        <h4 class="fs-4 fw-normal">Main Tasks:</h4>
        <ul>
          <li>Train and validate YOLO v7 and YOLO v9 on the same dataset.</li>
          <li>Compare detection metrics (accuracy, recall, mAP, etc.) and analyze results.</li>
          <li>Swap IOU Tracker for ByteTrack and evaluate ID persistence and tracking accuracy.</li>
          <li>Visualize and quantitatively compare detection/tracking outputs in both model and real-world settings.</li>
        </ul>
        <h4 class="fs-4 fw-normal">Outcome:</h4>
        <p>Demonstrated significant improvements in overtopping detection and tracking accuracy with YOLO v9 and ByteTrack, and presented quantitative performance differences arising from the model upgrades.</p>
      </div>
      <div class="mb-4">
        <h3>Application & Evaluation of DiffusionDet for Wave Overtopping Detection</h3>
        <h4 class="fs-4 fw-normal">Objective:</h4>
        <p>Apply the diffusion‑based detection model DiffusionDet to real breakwater overtopping data instead of the conventional YOLO model and evaluate its detection performance.</p>
        <h4 class="fs-4 fw-normal">Main Tasks:</h4>
        <ul>
          <li>Understand the DiffusionDet architecture and fine‑tune it for real‑world overtopping data.</li>
          <li>Analyze detection performance with precision, recall, mAP, etc.</li>
          <li>Compare results against the existing YOLO model to assess performance gains.</li>
          <li>Visualize detection outputs in the real environment and evaluate quantitatively using RMSE and MAE.</li>
        </ul>
        <h4 class="fs-4 fw-normal">Outcome:</h4>
        <p>Confirmed that DiffusionDet enhances overtopping detection under varying resolution and lighting conditions, demonstrating superior robustness and accuracy compared to YOLO.</p>
      </div>
      <div class="mb-4">
        <h3>Ultrasound Blind Zone Restoration using Lightweight U-Net-based Deep Learning</h3>
        <h4 class="fs-4 fw-normal">Objective:</h4>
        <p>Replace conventional filtering techniques with a lightweight U-Net-based deep learning model to restore blind zones in ultrasound images, aiming for high perceptual quality and real-time inference capability.</p>
        <h4 class="fs-4 fw-normal">Main Tasks:</h4>
        <ul>
          <li>Design and implement a U-Net-based architecture tailored for blind zone restoration in ultrasound imaging.</li>
          <li>Apply model pruning and lightweight module design to enable inference under 15 ms on edge devices.</li>
          <li>Evaluate restoration performance using SSIM, PSNR, and clinical interpretability under various masking patterns.</li>
          <li>
             Compare restoration quality and speed with traditional filtering methods and GAN-based approaches.</li>
          <li>
             Validate the model on real ultrasound datasets and optimize for integration into portable diagnostic systems.</li>
        </ul>
        <h4 class="fs-4 fw-normal">Outcome:</h4>
        <p>Confirmed that the proposed lightweight U-Net model outperforms traditional filtering methods, achieving fast (<15 ms) and high-quality restoration in blind zones with improved SSIM and PSNR metrics.</p>
      </div>
    </div>
  </section>
  <hr class="m-0">
  <!-- Awards-->
  <section class="resume-section" id="awards">
    <div class="resume-section-content">
      <h2 class="mb-5">Awards &amp; Certifications</h2>
      <ul class="fa-ul mb-0">
        <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>                            Capstone Design Project Excellence Award
          <p>Achieved outstanding performance in the Capstone Design Project organized by the AI Education Institute at the Korea University of Foreign Studies.</p>
          <p>팀명 : 각자의 새벽</p>
        </li>
        <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>                            Lg Aimers 5th class
          <p>Ranked 43rd out of 740 teams in the product defect determination project.</p>
          <p>팀명 : 각자의 새벽</p><span class="sreen"><a href="https://github.com/LGAimers-junebrothers?view_as=public">https://github.com/LGAimers-junebrothers?view_as=public</a></span>
          <p></p>
        </li>
        <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>                             HAI(하이)! - Hecto AI Challenge : 2025 상반기 헥토 채용 AI 경진대회
          <p>Ranked 21st out of 748 teams in a competition to develop an AI model for classifying car models based on real used car images.</p>
          <p>팀명 : 두더띠</p><span class="sreen"><a href="https://github.com/orgs/DACON-HAI/repositories">https://github.com/LGAimers-junebrothers?view_as=public</a></span>
          <p></p>
        </li>
      </ul>
    </div>
  </section>
</div>
<!-- Bootstrap core JS-->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
<!-- Core theme JS-->
<script src="js/scripts.js"></script>