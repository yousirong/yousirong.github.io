doctype html
head
  meta(charset='utf-8')
  meta(name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no')
  meta(name='description' content='')
  meta(name='author' content='')
  title yousirong CV
  link(rel='icon' type='image/x-icon' href='assets/img/favicon.ico')
  // Font Awesome icons (free version)
  script(src='https://use.fontawesome.com/releases/v6.3.0/js/all.js' crossorigin='anonymous')
  // Google fonts
  link(href='https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700' rel='stylesheet' type='text/css')
  link(href='https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i' rel='stylesheet' type='text/css')
  // Core theme CSS (includes Bootstrap)
  link(href='css/styles.css' rel='stylesheet')
// Navigation
nav#sideNav.navbar.navbar-expand-lg.navbar-dark.bg-primary.fixed-top
  a.navbar-brand.js-scroll-trigger(href='#page-top')
    span.d-block.d-lg-none JuneyongLee CV
    span.d-none.d-lg-block
      img.img-fluid.img-profile.rounded-circle.mx-auto.mb-2(src='assets/img/profile.jpg' alt='...')
  button.navbar-toggler(type='button' data-bs-toggle='collapse' data-bs-target='#navbarResponsive' aria-controls='navbarResponsive' aria-expanded='false' aria-label='Toggle navigation')
    span.navbar-toggler-icon
  #navbarResponsive.collapse.navbar-collapse
    ul.navbar-nav
      li.nav-item
        a.nav-link.js-scroll-trigger(href='#about') About
      li.nav-item
        a.nav-link.js-scroll-trigger(href='#publications') Publications
      li.nav-item
        a.nav-link.js-scroll-trigger(href='#education') Education
      li.nav-item
        a.nav-link.js-scroll-trigger(href='#skills') Skills
      li.nav-item
        a.nav-link.js-scroll-trigger(href='#interests') Research project
      li.nav-item
        a.nav-link.js-scroll-trigger(href='#awards') Awards
// Page Content
.container-fluid.p-0
  // About
  section#about.resume-section
    .resume-section-content
      h1.mb-0
        | JUNEYONG
        span.text-primary LEE
      .subheading.mb-5
        | Seoul, Republic of Korea  &middot; +82 10-5384-7822 &middot;
        a(href='mailto:diziyong@hufs.ac.kr') diziyong@hufs.ac.kr
      p.lead.mb-5
        | Hello, I am June-yong Lee, a master's student in Computer Engineering at Hankuk University of Foreign Studies.
        | My research focuses on developing transformer-based diffusion models for autonomous driving applications, with expertise in deep learning, computer vision, generative AI, and multimodal learning.
        | I have published research on video scene understanding using lightweight CNN-based models, particularly in driver assault detection, featured in the Journal of the Korean Institute of Information Scientists and Engineers (KIISE). Additionally, I have extensive experience in developing responsive web interfaces, frontend and backend development, and web crawling technologies.
        | Currently, I am actively researching multimodal diffusion transformers, aiming to enhance AI-driven solutions for precision medicine, environmental monitoring, and real-time detection and tracking systems.
      .social-icons
        a.social-icon(href='https://github.com/yousirong')
          i.fab.fa-github
        a.social-icon(href='https://scholar.google.com/citations?hl=ko&view_op=list_works&authuser=2&gmla=AFix5MZtqvevqzAeIhXMiafiBydfjIGYBE9MqJrFJ-getmKb7ggOrjFXHU6xSQB1MwIpcABG6BxX8uDZHHWsysThrITyAy1KJ_3apoPWzonXcUobFA&user=VAbPjjoAAAAJ')
          i.fa-solid.fa-graduation-cap
        a.social-icon(href='https://www.instagram.com/juneyong_d.v/')
          i.fab.fa-instagram
        a.social-icon(href='https://www.linkedin.com/in/juneyong-%E2%80%8Dlee-05b09733a/')
          i.fab.fa-linkedin-in


  hr.m-0
  // Publications
  section#publications.resume-section
    .resume-section-content
      h2.mb-5 Publications
      .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
        .flex-grow-1
          h3.mb-0
            | ADPDiT: A Multimodal Diffusion Transformer for Predicting Alzheimer's Disease Progression and Generating Brain Image
          .subheading.mb-3 Journal undecided
          p
            | ADPDiT (Alzheimer’s Disease Progression Diffusion Trans- former) is a novel multimodal framework that integrates brain MRI data with structured textual metadata to predict Alzheimer’s disease (AD) progression and generate personalized, progression-conditioned AD brain images. 
            | AD is a progressive neurodegenerative disorder with complex pathology, and conventional single-modality diagnostic approaches such as brain imaging or cognitive assessments fail to capture its full complex- ity.
            | To overcome these limitations, ADPDiT employs a diffusion transformer with cross-attention modules to effectively fuse patient-specific anatomical features with auxiliary metadata. 
            | The model also leverages a VAE-based latent space and incorporates Rotary Position Encoding (RoPE) to enhance the alignment between image and text embeddings, thereby accelerating convergence and improving accuracy.
            | In this study, brain MRI data from 1,171 participants in the Alzheimer’s Disease Neu- roimaging Initiative (ADNI) dataset, comprising 377 cognitively normal individuals, 540 mild cognitive impairment cases, and 254 AD patients, were used for training and evaluation.
            | The dataset was rigorously pre- processed with image alignment, normalization, spatial resolution adjustment, and histogram equalization to ensure high-quality inputs. 
            | Additionally, clinical metadata including cognitive test scores (MMSE, CDR, etc.) were embedded in the latent space to guide the generative process.
            | By combining multimodal conditioning with transformer-based diffusion modeling, ADPDiT offers a comprehensive approach to AD diagnosis and research, providing insights into disease progression and facilitating the development of precision medicine tools for neurodegenerative disorders.
            | This study demonstrates that ADPDiT, through its integration of dif- fusion processes and multimodal data, is a promising tool for advancing precision medicine in the diagnosis and management of AD.
          span.sreen
            a(href='https://github.com/Deep-Generative-Models-research') https://github.com/Deep-Generative-Models-research
          p
            span.badge.text-body.border.border-1 Alzheimer’s Disease (AD)
            span.badge.text-body.border.border-1 Text-Guided Image Generation
            span.badge.text-body.border.border-1 Brain MRI Generation
        .flex-shrink-0
          span.text-primary 1st semester 2025

      .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
        .flex-grow-1
          h3.mb-0
            | Lightweight Temporal Segment Network for Video Scene Understanding:
            | Validation in Driver Assault Detection
          .subheading.mb-3 Korean Institute of Information Scientists and Engineers - Journal of KIISE(JOK)
          p
            | There has been increasing number of driver assaults in transportation such as taxis and buses in the past years.
            | It can be especially difficult to respond quickly to assaults on drivers by drunks late at night.
            | To address this issue, our research team proposes a lightweight CNN-based Temporal Segment Network (TSN) model,
            | which can detect driver assaults by passengers in real time.
            | The TSN model efficiently processes videos by sampling a small number of image frames and is divided into two streams for learning:
            | one for spatial information processing and the other for temporal information processing.
            | Convolutional neural networks are employed in each stream. In this research,
            | we apply a lightweight CNN architecture, MobileOne, significantly reducing the model size while demonstrating improved accuracy even with limited computing resources.
            | The model is expected to contribute to rapid response and prevention of hazardous situations for drivers by being integrated into vehicular driver monitoring systems.
          span.sreen
            a(href='https://github.com/HUFSuperman/HUFS_SavingDriver') https://github.com/HUFSuperman/HUFS_SavingDriver
          p
            span.badge.text-body.border.border-1 Temporal Segment Network
            span.badge.text-body.border.border-1 Lightweight CNN Architecture
            span.badge.text-body.border.border-1 Assault Recognition
            span.badge.text-body.border.border-1 Abnormal Behavior
        .flex-shrink-0
          span.text-primary 1st semester 2024
      .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
        .flex-grow-1
          h3.mb-0
            | Research on Developing a Responsive Web Interface for Small Businesses Using React
          .subheading.mb-3 Collaboration with PeopleCat Co., Ltd.
          p
            | Although large corporations have established sales databases for efficient sales
            | activities, small-scale entrepreneurs need a system that provides an interface that anyone
            | can easily manage, offering diverse and complex information. This paper proposes the use
            | of React technology, which can also operate on crawling servers that automatically collect
            | store information.
            | Furthermore, it suggests the development of a responsive web user interface that can be conveniently used in both mouse
            | and keyboard-based desktop environments as well as touch-based smartphone environments,
            | utilizing React technology for theeffective delivery of various data. The proposed methods anticipate rapid retrieval of large
            | volumes of data due to the adoption of asynchronous function processing in React technology,
            | an improvement over traditional JavaScript methods.
          span.sreen
            a(href='https://github.com/yousirong/CAPSTONE_AWS') https://github.com/yousirong/CAPSTONE_AWS
          p
            span.badge.text-body.border.border-1 Responsive Web Interface
            span.badge.text-body.border.border-1 React
            span.badge.text-body.border.border-1 Asynchronous Processing
            span.badge.text-body.border.border-1
              | Information Architecture Design
        .flex-shrink-0
          span.text-primary 2nd semester 2023
      //
        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="flex-grow-1">
        <h3 class="mb-0">Junior Web Designer</h3>
        <div class="subheading mb-3">Shout! Media Productions</div>
        <p>Podcasting operational change management inside of workflows to establish a framework. Taking seamless key performance indicators offline to maximise the long tail. Keeping your eye on the ball while performing a deep dive on the start-up mentality to derive convergence on cross-platform integration.</p>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">July 2010 - December 2011</span></div>
        </div>
        <div class="d-flex flex-column flex-md-row justify-content-between">
        <div class="flex-grow-1">
        <h3 class="mb-0">Web Design Intern</h3>
        <div class="subheading mb-3">Shout! Media Productions</div>
        <p>Collaboratively administrate empowered markets via plug-and-play networks. Dynamically procrastinate B2C users after installed base benefits. Dramatically visualize customer directed convergence without revolutionary ROI.</p>
        </div>
        <div class="flex-shrink-0"><span class="text-primary">September 2008 - June 2010</span></div>
        </div>
  hr.m-0
  // Education
  section#education.resume-section
    .resume-section-content
      h2.mb-5 Education
      .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
        .flex-grow-1
          h3.mb-0 Master course, Korea University of Foreign Studies
          .subheading.mb-3 Computer Science
          div Computer Science - AI Track
          p GPA: 4.33
        .flex-shrink-0
          span.text-primary March 2024 ~ present
      .d-flex.flex-column.flex-md-row.justify-content-between
        .flex-grow-1
          h3.mb-0 Bachelor&apos;s degree, Korea University of Foreign Studies
          .subheading.mb-3 Computer and Electronic Systems Engineering Major
          p GPA: 3.50
        .flex-shrink-0
          span.text-primary March 2021 - February 2024
      .d-flex.flex-column.flex-md-row.justify-content-between
        .flex-grow-1
          h3.mb-0 Bachelor course, Change of Major
          .subheading.mb-3 Computer Science Major
        .flex-shrink-0
          span.text-primary March 2018 - February 2019
      .d-flex.flex-column.flex-md-row.justify-content-between
        .flex-grow-1
          h3.mb-0 Bachelor course, Admission
          .subheading.mb-3 Statistics and Data Science Major
        .flex-shrink-0
          span.text-primary March 2017 - February 2018
  hr.m-0
  // Skills
  section#skills.resume-section
    .resume-section-content
      h2.mb-5 Skills
      .subheading.mb-3 Programming Languages & Tools
      ul.list-inline.dev-icons
        li.list-inline-item
          a(href='https://www.python.org/' title='Python')
            img(src='https://skillicons.dev/icons?i=py' alt='Python' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://pytorch.org/' title='PyTorch')
            img(src='https://skillicons.dev/icons?i=pytorch' alt='PyTorch' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://www.linux.org/' title='Linux')
            img(src='https://skillicons.dev/icons?i=linux' alt='Linux' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://www.docker.com/' title='Docker')
            img(src='https://skillicons.dev/icons?i=docker' alt='Docker' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://kubernetes.io/' title='Kubernetes')
            img(src='https://skillicons.dev/icons?i=kubernetes' alt='Kubernetes' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://www.latex-project.org/' title='LaTeX')
            img(src='https://skillicons.dev/icons?i=latex' alt='LaTeX' style='width:60px; height:60px;')
      .subheading.mb-3 Workspace
      ul.list-inline.dev-icons
        li.list-inline-item
          a(href='https://git-scm.com/' title='Git')
            img(src='https://skillicons.dev/icons?i=git' alt='Git' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://code.visualstudio.com/' title='VSCode')
            img(src='https://skillicons.dev/icons?i=vscode' alt='VSCode' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://aws.amazon.com/' title='AWS')
            img(src='https://skillicons.dev/icons?i=aws' alt='AWS' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://www.figma.com/' title='Figma')
            img(src='https://skillicons.dev/icons?i=figma' alt='Figma' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://www.notion.so/' title='Notion')
            img(src='https://skillicons.dev/icons?i=notion' alt='Notion' style='width:60px; height:60px;')
        li.list-inline-item
          a(href='https://discord.com/' title='Discord')
            img(src='https://skillicons.dev/icons?i=discord' alt='Discord' style='width:60px; height:60px;')
  hr.m-0
  // Interests
  section#interests.resume-section
    .resume-section-content
      h2.mb-5 Research Projects
      .mb-4
        h3 Ultrasound Blind Zone Restoration using Lightweight U-Net-based Deep Learning
        h4.fs-4.fw-normal Objective:
        p
          | Replace conventional filtering techniques with a lightweight U-Net-based deep learning model to restore blind zones in ultrasound images, aiming for high perceptual quality and real-time inference capability.
        h4.fs-4.fw-normal Main Tasks:
        ul
          li
            | Design and implement a U-Net-based architecture tailored for blind zone restoration in ultrasound imaging.
          li
            | Apply model pruning and lightweight module design to enable inference under 15 ms on edge devices.
          li
            | Evaluate restoration performance using SSIM, PSNR, and clinical interpretability under various masking patterns.
          li 
            | Compare restoration quality and speed with traditional filtering methods and GAN-based approaches.
          li 
            | Validate the model on real ultrasound datasets and optimize for integration into portable diagnostic systems.
        h4.fs-4.fw-normal Outcome:
        p
          | Confirmed that the proposed lightweight U-Net model outperforms traditional filtering methods, achieving fast (<15 ms) and high-quality restoration in blind zones with improved SSIM and PSNR metrics.
      .mb-4
        h3 Application & Evaluation of DiffusionDet for Wave Overtopping Detection
        h4.fs-4.fw-normal Objective:
        p
          | Apply the diffusion‑based detection model DiffusionDet to real breakwater overtopping data instead of the conventional YOLO model and evaluate its detection performance.
        h4.fs-4.fw-normal Main Tasks:
        ul
          li
            | Understand the DiffusionDet architecture and fine‑tune it for real‑world overtopping data.
          li
            | Analyze detection performance with precision, recall, mAP, etc.
          li
            | Compare results against the existing YOLO model to assess performance gains.
          li
            | Visualize detection outputs in the real environment and evaluate quantitatively using RMSE and MAE.
        h4.fs-4.fw-normal Outcome:
        p
          | Confirmed that DiffusionDet enhances overtopping detection under varying resolution and lighting conditions, demonstrating superior robustness and accuracy compared to YOLO.
      .mb-4
        h3 Wave Overtopping Detection & Tracking Experiment with YOLO v9 and ByteTrack
        h4.fs-4.fw-normal Objective:
        p
          | Upgrade the detection model from YOLO v7 to YOLO v9 on both a frontal hydraulic model overtopping dataset and a real breakwater overtopping region, then replace the IOU Tracker with ByteTrack to compare and analyze detection and tracking performance.
        h4.fs-4.fw-normal Main Tasks:
        ul
          li
            | Train and validate YOLO v7 and YOLO v9 on the same dataset.
          li
            | Compare detection metrics (accuracy, recall, mAP, etc.) and analyze results.
          li
            | Swap IOU Tracker for ByteTrack and evaluate ID persistence and tracking accuracy.
          li
            | Visualize and quantitatively compare detection/tracking outputs in both model and real-world settings.
        h4.fs-4.fw-normal Outcome:
        p
          | Demonstrated significant improvements in overtopping detection and tracking accuracy with YOLO v9 and ByteTrack, and presented quantitative performance differences arising from the model upgrades.

      .mb-4
        h3 Conversion of Restored Rrs Data to Chl-a and Generation of Difference Map
        h4.fs-4.fw-normal Objective:
        p
          | Convert restored Remote Sensing Reflectance (Rrs) data into Chlorophyll-a (Chl‑a) and visualize spatial distribution errors through a Difference Map using composite data.
        h4.fs-4.fw-normal Main Tasks:
        ul
          li
            | Process GOCI data captured 8 times a day into a single daily dataset by averaging pixel values.
          li
            | Select specific coordinates in the Saemangeum or Nakdong River region to convert restored Rrs data to Chl‑a and analyze results.
          li
            | Calculate the difference between restored results and actual GOCI data, visualizing it using MinMaxScaler with a range of ‑20 to +20, represented in color scale.
        h4.fs-4.fw-normal Outcome:
        p
          | While successful synthesis results from Rrs to Chl‑a are rare globally, the study introduced a quantitative evaluation method using Difference Maps to assess restoration performance.
      .mb-4
        h3 Development of a Supervised Learning Model for Restoring Gaps in Chl‑a Composite Data
        h4.fs-4.fw-normal Objective:
        p
          | Develop a deep learning model to restore missing regions in Chl‑a composite data, averaged over 8 days.
        h4.fs-4.fw-normal Main Tasks:
        ul
          li
            | Convert UST21 dataset into 8‑day moving averages for model training. For example, calculate averages for January 1–8 and January 2–9, and so on.
          li
            | Focus on central regions around Saemangeum and Nakdong River but adjust the area towards the open sea if data availability is limited.
          li
            | Train the RFRNet model with masked data for restoration tasks.
        h4.fs-4.fw-normal Outcome:
        ul
          li
            | Compare restored results with MODIS 8‑day average data to evaluate performance.
          li
            | Conduct quantitative analysis of restoration results for Nakdong River and Saemangeum regions using RMSE, MAE, and R² metrics.
          li
            | Apply smoothing techniques for missing data when testing images larger than the traditional 256×256 patch size.

  hr.m-0
  // Awards
  section#awards.resume-section
    .resume-section-content
      h2.mb-5 Awards &amp; Certifications
      ul.fa-ul.mb-0
        li
          span.fa-li
            i.fas.fa-trophy.text-warning
          |                              2025 Samsung Collegiate Programming Challenge : AI 챌린지
          p Ranked 3rd out of 242 teams in a competition to develop a multimodal AI model that answers multiple-choice questions about a user's daily photos from their smartphone gallery.
          p 팀명 : 각자의 새벽
          span.sreen
            a(href='https://github.com/samsung-man/SCPC_2025_Code') https://github.com/samsung-man/SCPC_2025_Code
          p
        li
          span.fa-li
            i.fas.fa-trophy.text-warning
          |                              HAI(하이)! - Hecto AI Challenge : 2025 상반기 헥토 채용 AI 경진대회
          p Ranked 21st out of 748 teams in a competition to develop an AI model for classifying car models based on real used car images.
          p 팀명 : 두더띠
          span.sreen
            a(href='https://github.com/DACON-HAI') https://github.com/DACON-HAI
          p
        li
          span.fa-li
            i.fas.fa-trophy.text-warning
          |                             Lg Aimers 5th class
          p Ranked 43rd out of 740 teams in the product defect determination project.

          p 팀명 : 각자의 새벽
          span.sreen
            a(href='https://github.com/LGAimers-junebrothers') https://github.com/LGAimers-junebrothers
          p
        li
          span.fa-li
            i.fas.fa-trophy.text-warning
          |                             Capstone Design Project Excellence Award
          p
            | Achieved outstanding performance in the Capstone Design Project organized by the AI Education Institute at the Korea University of Foreign Studies.
          p
          a(href="assets/capstone.pdf" target="_blank" rel="noopener noreferrer") 팀명 : 각자의 새벽
          p



          


// Bootstrap core JS
script(src='https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js')
// Core theme JS
script(src='js/scripts.js')
