doctype html
html(lang='en')
  head
    meta(charset='utf-8')
    meta(name='viewport', content='width=device-width, initial-scale=1, shrink-to-fit=no')
    meta(name='description', content='Juneyong Lee CV')
    meta(name='author', content='Juneyong Lee')
    title Juneyong Lee - CV
    link(rel='icon', type='image/x-icon', href='assets/img/favicon.ico')
    // Font Awesome icons (free version)
    script(src='https://use.fontawesome.com/releases/v6.3.0/js/all.js', crossorigin='anonymous')
    // Google fonts
    link(href='https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700', rel='stylesheet', type='text/css')
    link(href='https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i', rel='stylesheet', type='text/css')
    // Core theme CSS (includes Bootstrap)
    link(href='css/styles.css', rel='stylesheet')

  body#page-top
    // Navigation
    nav#sideNav.navbar.navbar-expand-lg.navbar-dark.bg-primary.fixed-top
      a.navbar-brand.js-scroll-trigger(href='#page-top')
        span.d-block.d-lg-none Juneyong Lee
        span.d-none.d-lg-block
          img.img-fluid.img-profile.rounded-circle.mx-auto.mb-2(src='assets/img/profile.jpg', alt='Profile Image')
      button.navbar-toggler(type='button', data-bs-toggle='collapse', data-bs-target='#navbarResponsive', aria-controls='navbarResponsive', aria-expanded='false', aria-label='Toggle navigation')
        span.navbar-toggler-icon
      #navbarResponsive.collapse.navbar-collapse
        ul.navbar-nav
          li.nav-item
            a.nav-link.js-scroll-trigger(href='#about') About
          li.nav-item
            a.nav-link.js-scroll-trigger(href='#publications') Publications
          li.nav-item
            a.nav-link.js-scroll-trigger(href='#education') Education
          li.nav-item
            a.nav-link.js-scroll-trigger(href='#skills') Skills
          li.nav-item
            a.nav-link.js-scroll-trigger(href='#interests') Research Projects
          li.nav-item
            a.nav-link.js-scroll-trigger(href='#awards') Awards

    // Page Content
    .container-fluid.p-0

      // About
      section#about.resume-section
        .resume-section-content
          h1.mb-0
            | JUNEYONG 
            span.text-primary LEE
          .subheading.mb-5
            | Seoul, Republic of Korea · +82 10-5384-7822 · 
            a(href='mailto:diziyong@hufs.ac.kr') diziyong@hufs.ac.kr
          p.lead.mb-5
            | I am a Master's student in Computer Science at Hankuk University of Foreign Studies, specializing in #[strong Multimodal Generative AI] and #[strong Autonomous AI Agent] systems. My expertise was demonstrated by securing #[strong 3rd place] in both the #[strong 2025 Samsung AI Challenge] and the #[strong 2025 Samsung Collegiate Programming Challenge].
            br
            br
            | My core research focuses on developing a novel #[strong Multimodal Diffusion Transformer] model that integrates MRI with clinical data to predict Alzheimer's disease progression and generate personalized brain imagery. Beyond this, I have hands-on experience applying AI to solve practical problems in diverse domains, including satellite data restoration and real-time video analysis.
            br
            br
            | I am passionate about building and advancing cutting-edge generative models and autonomous systems to tackle complex, real-world challenges.
          .social-icons
            a.social-icon(href='https://github.com/yousirong', target='_blank')
              i.fab.fa-github
            a.social-icon(href='https://scholar.google.com/citations?user=VAbPjjoAAAAJ&hl=ko', target='_blank')
              i.fa-solid.fa-graduation-cap
            a.social-icon(href='https://www.instagram.com/juneyong_d.v/', target='_blank')
              i.fab.fa-instagram
            a.social-icon(href='www.linkedin.com/in/juneyong-‍lee-05b09733a', target='_blank')
              i.fab.fa-linkedin-in

      hr.m-0

      // Publications
      section#publications.resume-section
        .resume-section-content
          h2.mb-5 Publications
          .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
            .flex-grow-1
              h3.mb-0 ADPDiT: A Multimodal Diffusion Transformer for Predicting Alzheimer's Disease Progression and Generating Brain Image
              .subheading.mb-3 Journal undecided
              p
                | ADPDiT (Alzheimer's Disease Progression Diffusion Transformer) is a novel multimodal framework that integrates brain MRI data with structured clinical metadata to predict Alzheimer's disease (AD) progression and generate personalized, progression-conditioned brain images. AI-based AD diagnosis using MRI requires longitudinal imaging data capturing disease state transitions over time. However, clinical practice faces significant challenges: patients may skip scheduled MRI appointments, and many datasets predominantly contain images from single disease states rather than progressive sequences. To address these limitations, ADPDiT employs predictive generation capabilities that can synthesize missing temporal MRI data, potentially enhancing existing AD prediction systems by providing continuous disease progression visualization. The model addresses the limitations of conventional single-modality diagnostic approaches by employing a diffusion transformer architecture with specialized cross-attention modules that effectively fuse patient-specific neuroimaging features with comprehensive clinical data. The core architecture features ADPDiTBlocks with self-attention, cross-attention, and feed-forward networks, utilizing Flash Attention optimization and Query-Key normalization for enhanced computational efficiency. The model incorporates 2D Rotary Position Encoding (RoPE) for spatial-aware image token processing and attention pooling mechanisms to integrate multi-scale clinical information. The framework operates on 256×256 resolution brain MRI slices, which are processed into patch embeddings within a VAE-based latent space. Training data comprises 619 unique patients from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, with 226,434 brain MRI slices distributed as: 341 mild cognitive impairment (MCI) patients, 141 AD patients, and 137 cognitively normal (CN) individuals. Clinical metadata includes comprehensive neuropsychological assessments (CDRSB, ADAS11, ADAS13, MMSE, RAVLT, MOCA, FAQ) embedded through learned representations and integrated via attention pooling, making it a comprehensive tool for AD research and precision medicine applications in neurodegenerative disease management.
              div
                a(href='https://github.com/Deep-Generative-Models-research', target='_blank') https://github.com/Deep-Generative-Models-research
              p.mt-3
                span.badge.text-bg-secondary.me-2 Alzheimer’s Disease (AD)
                span.badge.text-bg-secondary.me-2 Text-Guided Image Generation
                span.badge.text-bg-secondary.me-2 Brain MRI Generation
            .flex-shrink-0
              span.text-primary 1st semester 2025
          .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
            .flex-grow-1
              h3.mb-0 Lightweight Temporal Segment Network for Video Scene Understanding: Validation in Driver Assault Detection
              .subheading.mb-3 Korean Institute of Information Scientists and Engineers - Journal of KIISE(JOK)
              p
                | There has been an increasing number of driver assaults in transportation such as taxis and buses in the past years. It can be especially difficult to respond quickly to assaults on drivers by drunks late at night. To address this issue, our research team proposes a lightweight CNN-based Temporal Segment Network (TSN) model, which can detect driver assaults by passengers in real time. The TSN model efficiently processes videos by sampling a small number of image frames and is divided into two streams for learning: one for spatial information processing and the other for temporal information processing. Convolutional neural networks are employed in each stream. In this research, we apply a lightweight CNN architecture, MobileOne, significantly reducing the model size while demonstrating improved accuracy even with limited computing resources. The model is expected to contribute to a rapid response and prevention of hazardous situations for drivers by being integrated into vehicular driver monitoring systems.
              div
                a(href='https://github.com/HUFSuperman/HUFS_SavingDriver', target='_blank') https://github.com/HUFSuperman/HUFS_SavingDriver
              p.mt-3
                span.badge.text-bg-secondary.me-2 Temporal Segment Network
                span.badge.text-bg-secondary.me-2 Lightweight CNN Architecture
                span.badge.text-bg-secondary.me-2 Assault Recognition
                span.badge.text-bg-secondary.me-2 Abnormal Behavior
            .flex-shrink-0
              span.text-primary 1st semester 2024
          .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
            .flex-grow-1
              h3.mb-0 Research on Developing a Responsive Web Interface for Small Businesses Using React
              .subheading.mb-3 Collaboration with PeopleCat Co., Ltd.
              p
                | Although large corporations have established sales databases for efficient sales activities, small-scale entrepreneurs need a system that provides an interface that anyone can easily manage, offering diverse and complex information. This paper proposes the use of React technology, which can also operate on crawling servers that automatically collect store information. Furthermore, it suggests the development of a responsive web user interface that can be conveniently used in both mouse and keyboard-based desktop environments as well as touch-based smartphone environments, utilizing React technology for the effective delivery of various data. The proposed methods anticipate rapid retrieval of large volumes of data due to the adoption of asynchronous function processing in React technology, an improvement over traditional JavaScript methods.
              div
                a(href='https://github.com/yousirong/CAPSTONE_AWS', target='_blank') https://github.com/yousirong/CAPSTONE_AWS
              p.mt-3
                span.badge.text-bg-secondary.me-2 Responsive Web Interface
                span.badge.text-bg-secondary.me-2 React
                span.badge.text-bg-secondary.me-2 Asynchronous Processing
                span.badge.text-bg-secondary.me-2 Information Architecture Design
            .flex-shrink-0
              span.text-primary 2nd semester 2023

      hr.m-0

      // Education
      section#education.resume-section
        .resume-section-content
          h2.mb-5 Education
          .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
            .flex-grow-1
              h3.mb-0 Hankuk University of Foreign Studies
              .subheading.mb-3 Master's course, Computer Science - AI Track
              p GPA: 4.33 / 4.5
            .flex-shrink-0
              span.text-primary March 2024 - Present
          .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
            .flex-grow-1
              h3.mb-0 Hankuk University of Foreign Studies
              .subheading.mb-3 Bachelor's degree, Computer and Electronic Systems Engineering
              p GPA: 3.50 / 4.5
            .flex-shrink-0
              span.text-primary March 2021 - February 2024
          .d-flex.flex-column.flex-md-row.justify-content-between.mb-5
            .flex-grow-1
              h3.mb-0 Hankuk University of Foreign Studies
              .subheading.mb-3 Bachelor's course (Change of Major) - Computer Science
            .flex-shrink-0
              span.text-primary March 2018 - February 2019
          .d-flex.flex-column.flex-md-row.justify-content-between
            .flex-grow-1
              h3.mb-0 Hankuk University of Foreign Studies
              .subheading.mb-3 Bachelor's course (Admission) - Statistics and Data Science
            .flex-shrink-0
              span.text-primary March 2017 - February 2018

      hr.m-0

      // Skills
      section#skills.resume-section
        .resume-section-content
          h2.mb-5 Skills
          .subheading.mb-3 Programming Languages & Tools
          ul.list-inline.dev-icons
            li.list-inline-item
              a(href='https://www.python.org/', title='Python', target='_blank')
                img(src='https://skillicons.dev/icons?i=py', alt='Python', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://pytorch.org/', title='PyTorch', target='_blank')
                img(src='https://skillicons.dev/icons?i=pytorch', alt='PyTorch', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://www.linux.org/', title='Linux', target='_blank')
                img(src='https://skillicons.dev/icons?i=linux', alt='Linux', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://www.docker.com/', title='Docker', target='_blank')
                img(src='https://skillicons.dev/icons?i=docker', alt='Docker', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://kubernetes.io/', title='Kubernetes', target='_blank')
                img(src='https://skillicons.dev/icons?i=kubernetes', alt='Kubernetes', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://www.latex-project.org/', title='LaTeX', target='_blank')
                img(src='https://skillicons.dev/icons?i=latex', alt='LaTeX', style='width:60px; height:60px;')
          .subheading.mb-3 Workspace
          ul.list-inline.dev-icons
            li.list-inline-item
              a(href='https://git-scm.com/', title='Git', target='_blank')
                img(src='https://skillicons.dev/icons?i=git', alt='Git', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://code.visualstudio.com/', title='VSCode', target='_blank')
                img(src='https://skillicons.dev/icons?i=vscode', alt='VSCode', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://aws.amazon.com/', title='AWS', target='_blank')
                img(src='https://skillicons.dev/icons?i=aws', alt='AWS', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://www.figma.com/', title='Figma', target='_blank')
                img(src='https://skillicons.dev/icons?i=figma', alt='Figma', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://www.notion.so/', title='Notion', target='_blank')
                img(src='https://skillicons.dev/icons?i=notion', alt='Notion', style='width:60px; height:60px;')
            li.list-inline-item
              a(href='https://discord.com/', title='Discord', target='_blank')
                img(src='https://skillicons.dev/icons?i=discord', alt='Discord', style='width:60px; height:60px;')

      hr.m-0

      // Interests
      section#interests.resume-section
        .resume-section-content
          h2.mb-5 Research Projects
          
          .d-flex.flex-column.flex-md-row.justify-content-between.mb-4
            .flex-grow-1
              h3.mb-0 Lightweight Ultrasound Blind Zone Restoration using Denoising Diffusion Restoration Models (DDRM)
              p
                | Developed a #[strong lightweight Denoising Diffusion Restoration Model (DDRM)] for #[strong real-time restoration] of blind zones in ultrasound images (inference <15ms on edge devices). Achieved superior perceptual quality and improved SSIM/PSNR metrics by optimizing the diffusion process and model architecture for on-device efficiency.

          .d-flex.flex-column.flex-md-row.justify-content-between.mb-4
            .flex-grow-1
              h3.mb-0 Large-Scale Oceanographic Data Restoration for East Asia using Recurrent Feature Reasoning (RFR)
              p
                | Successfully restored missing data in GOCI and UST21 satellite imagery across the #[strong entire East Asia region], expanding significantly beyond the initial Saemangeum and Nakdong River areas. Utilized a #[strong Recurrent Feature Reasoning (RFR) model] for high-fidelity inpainting of Chlorophyll-a composite maps, enabling comprehensive environmental monitoring on a large geographical scale.

          .d-flex.flex-column.flex-md-row.justify-content-between.mb-4
            .flex-grow-1
              h3.mb-0 Application & Evaluation of DiffusionDet for Wave Overtopping Detection
              p
                | Applied and fine-tuned the #[strong DiffusionDet] model for real-world #[strong breakwater wave overtopping detection], demonstrating #[strong superior robustness and accuracy] over the conventional YOLO model, especially under varying resolution and lighting conditions.

          .d-flex.flex-column.flex-md-row.justify-content-between.mb-4
            .flex-grow-1
              h3.mb-0 Wave Overtopping Detection & Tracking Experiment with YOLO v9 and ByteTrack
              p
                | Upgraded object detection from YOLO v7 to #[strong YOLO v9] and replaced IOU Tracker with #[strong ByteTrack] for wave overtopping. Demonstrated significant improvements in both detection and #[strong tracking accuracy (ID persistence)] through rigorous quantitative comparison.
            
            
      hr.m-0

      // Awards
      section#awards.resume-section
        .resume-section-content
          h2.mb-5 Awards & Certifications
          ul.fa-ul.mb-0
            li.mb-4
              span.fa-li
                i.fas.fa-trophy.text-warning
              h4.mb-1 AI Co-Scientist : 2025 Samsung AI Challenge
              .subheading.mb-2 Team: 각자의 새벽 
              p.mb-2
                | #[strong Secured 3rd place] in a challenge requiring the design and implementation of a #[strong Multi-AI Agent Collaboration] system capable of #[strong autonomously] handling the entire model development lifecycle (code generation, tuning, etc.) with minimal human intervention.
              a(href='https://github.com/samsung-man/Ai_Co_Sci_2025.git', target='_blank') View Project on GitHub
            li.mb-4
              span.fa-li
                i.fas.fa-trophy.text-warning
              h4.mb-1 2025 Samsung Collegiate Programming Challenge
              .subheading.mb-2 Team: 각자의 새벽 
              p.mb-2
                | #[strong Achieved 3rd place out of 242 teams] by successfully developing a #[strong multimodal AI model] designed to answer multiple-choice questions based on analyzing a user's daily smartphone photo gallery.
              a(href='https://github.com/samsung-man/SCPC_2025_Code', target='_blank') View Project on GitHub
            li.mb-4
              span.fa-li
                i.fas.fa-trophy.text-warning
              h4.mb-1 HAI! - Hecto AI Challenge
              .subheading.mb-2 Team: 두더띠 (Dudotti)
              p.mb-2
                | #[strong Ranked 21st out of 748 teams] in a competition to develop an AI model for #[strong classifying car models] based on real used car images.
              a(href='https://github.com/DACON-HAI', target='_blank') View Project on GitHub
            li.mb-4
              span.fa-li
                i.fas.fa-trophy.text-warning
              h4.mb-1 LG Aimers 5th Class
              .subheading.mb-2 Team: 각자의 새벽 
              p.mb-2
                | #[strong Ranked 43rd out of 740 teams] in the #[strong product defect determination] project.
              a(href='https://github.com/LGAimers-junebrothers', target='_blank') View Project on GitHub
            li
              span.fa-li
                i.fas.fa-trophy.text-warning
              h4.mb-1 Capstone Design Project Excellence Award
              .subheading.mb-2 Hankuk University of Foreign Studies, AI Education Institute
              p.mb-2
                | #[strong Awarded the Excellence Award] for outstanding performance in the Capstone Design Project.
              a(href="assets/capstone.pdf", target="_blank") View Certificate


    // Bootstrap core JS
    script(src='https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js')
    // Core theme JS
    script(src='js/scripts.js')